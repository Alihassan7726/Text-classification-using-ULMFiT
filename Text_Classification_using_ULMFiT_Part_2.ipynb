{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Classification using ULMFiT Part#2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM9b6rbz0xvhjIZfUP6fe/P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alihassan7726/Text-classification-using-ULMFiT/blob/main/Text_Classification_using_ULMFiT_Part_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkV2MLAmrXYS"
      },
      "source": [
        "# import libraries\n",
        "import fastai\n",
        "from fastai import *\n",
        "from fastai.text import * \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from functools import partial\n",
        "import io\n",
        "import os\n",
        "pd.set_option('display.width',1000)\n",
        "pd.set_option('max_colwidth', 1000) \n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "3PGsB0MBryEJ",
        "outputId": "ce851381-958b-4100-9ffe-a80921ff1376"
      },
      "source": [
        "#import dataset\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "dataset = fetch_20newsgroups(shuffle=True, random_state=1, remove=('headers', 'footers', 'quotes'))\n",
        "# create a dataframe\n",
        "df = pd.DataFrame({'label':dataset.target,\n",
        "                   'text':dataset.data})\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 20news dataset. This may take a few minutes.\n",
            "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17</td>\n",
              "      <td>Well i'm not sure about the story nad it did seem biased. What\\nI disagree with is your statement that the U.S. Media is out to\\nruin Israels reputation. That is rediculous. The U.S. media is\\nthe most pro-israeli media in the world. Having lived in Europe\\nI realize that incidences such as the one described in the\\nletter have occured. The U.S. media as a whole seem to try to\\nignore them. The U.S. is subsidizing Israels existance and the\\nEuropeans are not (at least not to the same degree). So I think\\nthat might be a reason they report more clearly on the\\natrocities.\\n\\tWhat is a shame is that in Austria, daily reports of\\nthe inhuman acts commited by Israeli soldiers and the blessing\\nreceived from the Government makes some of the Holocaust guilt\\ngo away. After all, look how the Jews are treating other races\\nwhen they got power. It is unfortunate.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>\\n\\n\\n\\n\\n\\n\\nYeah, do you expect people to read the FAQ, etc. and actually accept hard\\natheism?  No, you need a little leap of faith, Jimmy.  Your logic runs out\\nof steam!\\n\\n\\n\\n\\n\\n\\n\\nJim,\\n\\nSorry I can't pity you, Jim.  And I'm sorry that you have these feelings of\\ndenial about the faith you need to get by.  Oh well, just pretend that it will\\nall end happily ever after anyway.  Maybe if you start a new newsgroup,\\nalt.atheist.hard, you won't be bummin' so much?\\n\\n\\n\\n\\n\\n\\nBye-Bye, Big Jim.  Don't forget your Flintstone's Chewables!  :) \\n--\\nBake Timmons, III</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>17</td>\n",
              "      <td>Although I realize that principle is not one of your strongest\\npoints, I would still like to know why do do not ask any question\\nof this sort about the Arab countries.\\n\\n   If you want to continue this think tank charade of yours, your\\nfixation on Israel must stop.  You might have to start asking the\\nsame sort of questions of Arab countries as well.  You realize it\\nwould not work, as the Arab countries' treatment of Jews over the\\nlast several decades is so bad that your fixation on Israel would\\nbegin to look like the biased attack that it is.\\n\\n   Everyone in this group recognizes that your stupid 'Center for\\nPolicy Research' is nothing more than a fancy name for some bigot\\nwho hates Israel.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11</td>\n",
              "      <td>Notwithstanding all the legitimate fuss about this proposal, how much\\nof a change is it?  ATT's last product in this area (a) was priced over\\n$1000, as I suspect 'clipper' phones will be; (b) came to the customer \\nwith the key automatically preregistered with government authorities. Thus,\\naside from attempting to further legitimize and solidify the fed's posture,\\nClipper seems to be \"more of the same\", rather than a new direction.\\n   Yes, technology will eventually drive the cost down and thereby promote\\nmore widespread use- but at present, the man on the street is not going\\nto purchase a $1000 crypto telephone, especially when the guy on the other\\nend probably doesn't have one anyway.  Am I missing something?\\n   The real question is what the gov will do in a year or two when air-\\ntight voice privacy on a phone line is as close as your nearest pc.  That\\nhas got to a problematic scenario for them, even if the extent of usage\\nnever surpasses the 'underground' stature of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10</td>\n",
              "      <td>Well, I will have to change the scoring on my playoff pool.  Unfortunately\\nI don't have time right now, but I will certainly post the new scoring\\nrules by tomorrow.  Does it matter?  No, you'll enter anyway!!!  Good!\\n\\n--\\n    Keith Keller\\t\\t\\t\\tLET'S GO RANGERS!!!!!\\n\\t\\t\\t\\t\\t\\tLET'S GO QUAKERS!!!!!\\n\\tkkeller@mail.sas.upenn.edu\\t\\tIVY LEAGUE CHAMPS!!!!</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     text\n",
              "0     17                                                                                                                                     Well i'm not sure about the story nad it did seem biased. What\\nI disagree with is your statement that the U.S. Media is out to\\nruin Israels reputation. That is rediculous. The U.S. media is\\nthe most pro-israeli media in the world. Having lived in Europe\\nI realize that incidences such as the one described in the\\nletter have occured. The U.S. media as a whole seem to try to\\nignore them. The U.S. is subsidizing Israels existance and the\\nEuropeans are not (at least not to the same degree). So I think\\nthat might be a reason they report more clearly on the\\natrocities.\\n\\tWhat is a shame is that in Austria, daily reports of\\nthe inhuman acts commited by Israeli soldiers and the blessing\\nreceived from the Government makes some of the Holocaust guilt\\ngo away. After all, look how the Jews are treating other races\\nwhen they got power. It is unfortunate.\\n\n",
              "1      0                                                                                                                                                                                                                                                                                                                                                                                                                                        \\n\\n\\n\\n\\n\\n\\nYeah, do you expect people to read the FAQ, etc. and actually accept hard\\natheism?  No, you need a little leap of faith, Jimmy.  Your logic runs out\\nof steam!\\n\\n\\n\\n\\n\\n\\n\\nJim,\\n\\nSorry I can't pity you, Jim.  And I'm sorry that you have these feelings of\\ndenial about the faith you need to get by.  Oh well, just pretend that it will\\nall end happily ever after anyway.  Maybe if you start a new newsgroup,\\nalt.atheist.hard, you won't be bummin' so much?\\n\\n\\n\\n\\n\\n\\nBye-Bye, Big Jim.  Don't forget your Flintstone's Chewables!  :) \\n--\\nBake Timmons, III\n",
              "2     17                                                                                                                                                                                                                                                                                                  Although I realize that principle is not one of your strongest\\npoints, I would still like to know why do do not ask any question\\nof this sort about the Arab countries.\\n\\n   If you want to continue this think tank charade of yours, your\\nfixation on Israel must stop.  You might have to start asking the\\nsame sort of questions of Arab countries as well.  You realize it\\nwould not work, as the Arab countries' treatment of Jews over the\\nlast several decades is so bad that your fixation on Israel would\\nbegin to look like the biased attack that it is.\\n\\n   Everyone in this group recognizes that your stupid 'Center for\\nPolicy Research' is nothing more than a fancy name for some bigot\\nwho hates Israel.\n",
              "3     11  Notwithstanding all the legitimate fuss about this proposal, how much\\nof a change is it?  ATT's last product in this area (a) was priced over\\n$1000, as I suspect 'clipper' phones will be; (b) came to the customer \\nwith the key automatically preregistered with government authorities. Thus,\\naside from attempting to further legitimize and solidify the fed's posture,\\nClipper seems to be \"more of the same\", rather than a new direction.\\n   Yes, technology will eventually drive the cost down and thereby promote\\nmore widespread use- but at present, the man on the street is not going\\nto purchase a $1000 crypto telephone, especially when the guy on the other\\nend probably doesn't have one anyway.  Am I missing something?\\n   The real question is what the gov will do in a year or two when air-\\ntight voice privacy on a phone line is as close as your nearest pc.  That\\nhas got to a problematic scenario for them, even if the extent of usage\\nnever surpasses the 'underground' stature of ...\n",
              "4     10                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Well, I will have to change the scoring on my playoff pool.  Unfortunately\\nI don't have time right now, but I will certainly post the new scoring\\nrules by tomorrow.  Does it matter?  No, you'll enter anyway!!!  Good!\\n\\n--\\n    Keith Keller\\t\\t\\t\\tLET'S GO RANGERS!!!!!\\n\\t\\t\\t\\t\\t\\tLET'S GO QUAKERS!!!!!\\n\\tkkeller@mail.sas.upenn.edu\\t\\tIVY LEAGUE CHAMPS!!!!"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYN44ptDr2MG",
        "outputId": "497baef9-0d50-4663-e65e-07b8547184b6"
      },
      "source": [
        "print(df.shape)\n",
        "dataset.target_names\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11314, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alt.atheism',\n",
              " 'comp.graphics',\n",
              " 'comp.os.ms-windows.misc',\n",
              " 'comp.sys.ibm.pc.hardware',\n",
              " 'comp.sys.mac.hardware',\n",
              " 'comp.windows.x',\n",
              " 'misc.forsale',\n",
              " 'rec.autos',\n",
              " 'rec.motorcycles',\n",
              " 'rec.sport.baseball',\n",
              " 'rec.sport.hockey',\n",
              " 'sci.crypt',\n",
              " 'sci.electronics',\n",
              " 'sci.med',\n",
              " 'sci.space',\n",
              " 'soc.religion.christian',\n",
              " 'talk.politics.guns',\n",
              " 'talk.politics.mideast',\n",
              " 'talk.politics.misc',\n",
              " 'talk.religion.misc']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qV3YmZ8LsAaQ",
        "outputId": "a0c34c0f-e6c0-40be-d3ef-1472df7381a8"
      },
      "source": [
        "# We will be taking only 2 classes ( for binary classification )\n",
        "df = df[df['label'].isin([1,10])]\n",
        "df = df.reset_index(drop = True)\n",
        "df['label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10    600\n",
              "1     584\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jS2wx1SAsBvy",
        "outputId": "50dcfe9f-ebdf-4472-8d16-52971fc1a0fb"
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer as wnl\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('stopwords')\n",
        "stpwrds = set(stopwords.words('english'))\n",
        "stpwrds.discard('not')\n",
        "stpwrds.discard('no')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwYZ887HsEHn",
        "outputId": "8cc38b73-3e3b-4b1f-ae86-1f9252ad33f0"
      },
      "source": [
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "IwIjxh7HsF3u",
        "outputId": "50ebfd19-0120-4873-8edb-9cf977c07157"
      },
      "source": [
        "def clean_text(text):  \n",
        "    lower = text.lower()\n",
        "    words = re.sub(r\"\\n\\t\\s\\r\",\" \",lower)\n",
        "    words = re.sub(r\"(@[A-Za-z]+)|([^A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \" \", lower ) \n",
        "    #words = re.sub(r\"\\n\\t\\s\\r\",\" \") \n",
        "    #pattren = r\"[^\\w\\s\\d]\"\n",
        "    #words = re.sub(pattren, \"\", lower)\n",
        "    words2 = words.split()\n",
        "    #print(words2)\n",
        "    final_words =  [wnl().lemmatize(word , pos = 'v') for word in words2 if word not in stopwords.words('english')]\n",
        "    final_words = ' '.join(final_words)\n",
        "    return(final_words)\n",
        "    \n",
        "df['Cleaned-text'] = df['text'].apply(clean_text)\n",
        "df.drop(columns = 'text', inplace = True)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>Cleaned-text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10</td>\n",
              "      <td>well change score playoff pool unfortunately time right certainly post new score rule tomorrow matter enter anyway good keith keller let go rangers let go quakers kkeller sas upenn edu ivy league champ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>archive name graphics resources list part last modify computer graphics resource list weekly post part last change april many faqs include list available archive site pit manager mit edu alias rtfm mit edu directory pub usenet news answer name faq archive appear archive name line top article faq archive graphics resources list part mail server machine send e mail message mail server manager mit edu contain keyword help without quote message body see many place list see item place find resource list information items change arrange subject order fir better k article limit plan change headers soon careful resource list key sure remain subject line place find resource list graphics editors public domain free shareware systems plot package molecular visualization stuff think make post bi weekly think line get change character front add line prepended remove line remove use diff locate change text c copyright nikolaos c fotis copy freely file provide keep copyright notice intact compile...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10</td>\n",
              "      <td>course mike ramsey one time captain buffalo prior trade pittsburgh currently penguins former captain real captain lemieux play rotate season even c mario even troy loney wear c pen jay</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10</td>\n",
              "      <td>promise would give name panther president huizenga announce team name announce bill torrey name first president panthers little bio sun sentinel torrey architect four consecutive stanley cup champion persident general manager new york islanders throughout years nhl bill torrey bow tie become much signature andre agassi hair panthers introduce uniform insignia ticket price information early next month meantime huizenga leave day day operation hand torrey bob clarke vp gm florida panthers choose name south florida nhl team focus attention endanger species florida panthers everglades national park big cypress national preserve part southwestern florida panther quickest strike cat torrey say hopefully way play ice bio torrey huizenga first man hire expansion islanders one responsible guide islanders four consecutive stanley cup championships first eight season consecutive win season executive vice president california golden seal torrey watch seal go play off second nhl season guess co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10</td>\n",
              "      <td>game adirondack cdi adirondack lead series first round springfield indians vs providence bruins gm springfield providence gm springfield providence gm providence springfield gm providence springfield gm springfield providence gm providence springfield gm springfield providence cd islanders vs adirondack red wing gm adirondack cdi gm cdi adirondack gm adirondack cdi gm adirondack cdi gm cdi adirondack gm adirondack cdi gm cdi adirondack baltimore skipjacks binghamton rangers gm baltimore binghamton gm baltimore binghamton gm binghamton baltimore gm binghamton baltimore gm baltimore binghamton gm binghmaton baltimore gm baltimore binghamton utica devil vs rochester americans gm utica rochester gm utica rochester gm rochester utica gm rochester utica gm utica rochester gm rochester utica gm utica rochester moncton hawk vs st john maple leaf gm st john moncton gm moncton vs st john halifax gm st john moncton gm st john moncton gm moncton vs st john halifax gm st john moncton gm moncton...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Cleaned-text\n",
              "0     10                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                well change score playoff pool unfortunately time right certainly post new score rule tomorrow matter enter anyway good keith keller let go rangers let go quakers kkeller sas upenn edu ivy league champ\n",
              "1      1  archive name graphics resources list part last modify computer graphics resource list weekly post part last change april many faqs include list available archive site pit manager mit edu alias rtfm mit edu directory pub usenet news answer name faq archive appear archive name line top article faq archive graphics resources list part mail server machine send e mail message mail server manager mit edu contain keyword help without quote message body see many place list see item place find resource list information items change arrange subject order fir better k article limit plan change headers soon careful resource list key sure remain subject line place find resource list graphics editors public domain free shareware systems plot package molecular visualization stuff think make post bi weekly think line get change character front add line prepended remove line remove use diff locate change text c copyright nikolaos c fotis copy freely file provide keep copyright notice intact compile...\n",
              "2     10                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 course mike ramsey one time captain buffalo prior trade pittsburgh currently penguins former captain real captain lemieux play rotate season even c mario even troy loney wear c pen jay\n",
              "3     10  promise would give name panther president huizenga announce team name announce bill torrey name first president panthers little bio sun sentinel torrey architect four consecutive stanley cup champion persident general manager new york islanders throughout years nhl bill torrey bow tie become much signature andre agassi hair panthers introduce uniform insignia ticket price information early next month meantime huizenga leave day day operation hand torrey bob clarke vp gm florida panthers choose name south florida nhl team focus attention endanger species florida panthers everglades national park big cypress national preserve part southwestern florida panther quickest strike cat torrey say hopefully way play ice bio torrey huizenga first man hire expansion islanders one responsible guide islanders four consecutive stanley cup championships first eight season consecutive win season executive vice president california golden seal torrey watch seal go play off second nhl season guess co...\n",
              "4     10  game adirondack cdi adirondack lead series first round springfield indians vs providence bruins gm springfield providence gm springfield providence gm providence springfield gm providence springfield gm springfield providence gm providence springfield gm springfield providence cd islanders vs adirondack red wing gm adirondack cdi gm cdi adirondack gm adirondack cdi gm adirondack cdi gm cdi adirondack gm adirondack cdi gm cdi adirondack baltimore skipjacks binghamton rangers gm baltimore binghamton gm baltimore binghamton gm binghamton baltimore gm binghamton baltimore gm baltimore binghamton gm binghmaton baltimore gm baltimore binghamton utica devil vs rochester americans gm utica rochester gm utica rochester gm rochester utica gm rochester utica gm utica rochester gm rochester utica gm utica rochester moncton hawk vs st john maple leaf gm st john moncton gm moncton vs st john halifax gm st john moncton gm st john moncton gm moncton vs st john halifax gm st john moncton gm moncton..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BG-FeXGz0Bni"
      },
      "source": [
        "## 1.Data For language Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaoZHh7QzeCU"
      },
      "source": [
        "# Batch-size and BPTT\n",
        "bs,bptt=32,40\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j58Oih3cBBu4"
      },
      "source": [
        "### Creating a forward Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "do3ZyEEWvr_0",
        "outputId": "5f072418-1c71-4ea5-95c6-1e515dd9904a"
      },
      "source": [
        "data_lm = (TextList.from_df(df, cols='Cleaned-text')\n",
        "                   .split_by_rand_pct(0.1 , seed = 42)\n",
        "                   .label_for_lm()\n",
        "                   .databunch(bs=bs, bptt=bptt))\n",
        "\n",
        "data_lm.save('data_lm.pkl')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/fastai/core.py:302: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return np.array(a, dtype=dtype, **kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "6Bzl1Gvhztsm",
        "outputId": "13ef59fe-ca8e-4d5c-f880-6e99027af16d"
      },
      "source": [
        "del(data_lm)\n",
        "path = \"/content/\"\n",
        "data_lm = load_data(path , 'data_lm.pkl', bs=bs, bptt=bptt)\n",
        "data_lm.show_batch()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>idx</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>part last modify computer graphics resource list weekly post part last change april many faqs include list available archive site pit manager mit edu alias rtfm mit edu directory pub usenet news answer name faq archive appear archive name line</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>european sit carry add xxunk available radiance xxunk xxunk se pub sipp sipp tar z sipp scan line z buffer phong shade renderer jonas xxunk jonas xxunk se xxunk fr xxunk vm pray ray tracer spd nff many non spd</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>car radio park lot thankful strong radio miles pittsburgh xxunk usually good believe pick middle day xxbos anyone really believe cap beat let xxunk pen may xxunk one game put definitely lose one game remember regular season mean much come</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>might except might something x windows pcs know use think good email xxunk xxunk gov au dv x common xxunk xxunk corporation xxunk x software use dv x yet read xxunk xxunk send sound pretty great allow multiple do machine</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>g pts ashton berube macinnis musil nieuwendyk otto paslawski ranheim reichel roberts skrudland stern suter yawney san jose power play scorer g pts garpenlov gaudreau kisio odgers wood vancouver los angeles first period los angeles robitaille gretzky sandstrom vancouver babych</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zgp-4PHrBIuT"
      },
      "source": [
        "### Creating a backward Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "0mpB9lz9ztky",
        "outputId": "93706688-330f-49d7-cd41-febd1475e4cc"
      },
      "source": [
        "data_bwd = load_data(path, 'data_lm.pkl', bs=bs, bptt=bptt, backwards=True)\n",
        "data_bwd.show_batch()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>idx</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>personally take hey streak unbeaten season regular far unbeaten game year last finals pen meet row blackhawks chicago tie streak playoff streak pen streak win game xxunk want might xxbos xxunk kiss xxunk hint siggraph xxunk xxunk g e surface</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>system software engineer navy xxunk sponsor maryland bethesda center research taylor david formerly center warfare surface naval division carderock june tuesday seminar reality virtual visualization scientific navy presentations call nd xxbos lssu maine xxbos xxunk also dve right xxunk wdve</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>use shit like play canucks xxunk first though big come probert win detroit think yes series playoff intense possibly war seven even maybe six wing though xxunk three two win might toronto playoffs lousy montreal find soon xxunk much leaf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>basis xxunk state xxunk lease current oilers community business northlands office political hold power wake want pocklington xxbos source c even maybe algorithm understand easy anybody surface two intersections problem xxbos claim com ibm xxunk xxunk rate clock doubt seriously</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>idl lang comp also see available discount quantity educational cost progress version mac windows microsoft sun sgi rs ibm hp ultrix vms dec environments windows ms motif look open applications idl gui build system base widget map xxunk statistics basic</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RX887rmWCAVr"
      },
      "source": [
        "## Fine-tuning the forward language model\n",
        "\n",
        "The vocabulary of the two datasets ( BBC and Wikipedia ) are slightly different, so when loading the weights, we take care to put the embedding weights at the right place, and we randomly initiliaze the embeddings for words in the BBC vocabulary that weren't in the wikitext-103 vocabulary of our pretrained model. \n",
        "\n",
        "This is all done in just 1st line of code below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "lhJzgk5Xztb7",
        "outputId": "75ea99ae-fbc8-4229-f94b-031ebef7821b"
      },
      "source": [
        "learn = language_model_learner(data_lm, AWD_LSTM, metrics=[accuracy, Perplexity()], path=path, wd=0.1).to_fp16(clip=0.1) # # Speeds up training on a GPU\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://s3.amazonaws.com/fast-ai-modelzoo/wt103-fwd.tgz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f58KF9NJztTM",
        "outputId": "aac3f137-a433-4651-dc27-f18501846cf8"
      },
      "source": [
        "lr = 1e-2\n",
        "#lr *= bs/48\n",
        "lr /= 8\n",
        "lr"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.00125"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "VMy2c2jNztIv",
        "outputId": "f3b9448e-c5ba-4fcb-df4c-24e12ade765f"
      },
      "source": [
        "# The Learner object we get is frozen by default, which means we only train the embeddings at first\n",
        "learn.fit_one_cycle(1, lr, moms=(0.8,0.7), wd=0.1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>perplexity</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>7.855065</td>\n",
              "      <td>6.969272</td>\n",
              "      <td>0.110937</td>\n",
              "      <td>1063.448975</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEZe15vICf4m"
      },
      "source": [
        "learn.save('1epoch') # It will create a file in learn.path/models/ named \"1epoch.pth\" that can be used to tune later"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ijgldb5mCvuB"
      },
      "source": [
        "learn = learn.load('1epoch')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enFnVBJNC1W3"
      },
      "source": [
        "# Then we unfreeze the model and fine-tune the whole thing for 10 epochs\n",
        "learn.unfreeze()\n",
        "learn.fit_one_cycle(8, lr/5, moms=(0.8,0.7), wd=0.1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RedckV1ZC7u_"
      },
      "source": [
        "# Once done we will save our encoder\n",
        "learn.save_encoder('fwd_enc')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgVz6uetDrzA"
      },
      "source": [
        "## Training the Backward Model\n",
        "\n",
        "We can't directly train a bidirectional RNN for language modeling, but we can always ensemble a forward and backward model. fastai provides a pretrained forward and backawrd model, so we can repeat the previous step to fine-tune the pretrained backward model. The command language_model_learner checks the data object you pass to automatically decide if it should use the pretrained forward or backward model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "sztZzbrhDnwg",
        "outputId": "e29858e1-2e15-432c-9bcf-d79dc49afcad"
      },
      "source": [
        "learn = language_model_learner(data_bwd, AWD_LSTM, metrics=[accuracy, Perplexity()], path=path, wd=0.1).to_fp16(clip=0.1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://s3.amazonaws.com/fast-ai-modelzoo/wt103-bwd.tgz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "vu79na5AD9Ez",
        "outputId": "a21bb028-6364-44f9-d54a-c3e3b7984ff3"
      },
      "source": [
        "# The rest of process is same\n",
        "\n",
        "lr = 0.00125\n",
        "learn.fit_one_cycle(1, lr, moms=(0.8,0.7), wd=0.1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>perplexity</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>8.320634</td>\n",
              "      <td>7.213185</td>\n",
              "      <td>0.081152</td>\n",
              "      <td>1357.208496</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VI0MuqDOEAEH"
      },
      "source": [
        "learn.unfreeze()\n",
        "learn.fit_one_cycle(8, lr/5, moms=(0.8,0.7), wd=0.1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7kSQHUIEC10"
      },
      "source": [
        "learn.save_encoder('bwd_enc')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljA4OwEdEnRA"
      },
      "source": [
        "# before tunning the classifier let us check how our model predicts some words given some context words from BBC news.\n",
        "\n",
        "TEXT = \"well change score playoff pool unfortunately time right certainly post new score rule tomorrow matter \"\n",
        "N_WORDS = 15\n",
        "N_SENTENCES = 2\n",
        "preds = [learn.predict(TEXT, N_WORDS, temperature=0.75) \n",
        "         for _ in range(N_SENTENCES)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0qV5oeqFP1Z",
        "outputId": "a1b54a7e-600e-46a0-fd65-0793a6cedf2d"
      },
      "source": [
        "preds"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['well change score playoff pool unfortunately time right certainly post new score rule tomorrow matter  go game ds win time one player good need game point one play game two',\n",
              " 'well change score playoff pool unfortunately time right certainly post new score rule tomorrow matter  xxbos xxbos thank thank get package mail e yes please thank contact require program use']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohor8EjgFfWA"
      },
      "source": [
        "## Building a classifier\n",
        "\n",
        "The classifier is a model that is a bit heavier, so we have lower the batch size.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "zHnX_stIFTwC",
        "outputId": "e933de71-0fae-4aca-dde0-4d211d449628"
      },
      "source": [
        "data_clas = (TextList.from_df(df, cols='Cleaned-text')\n",
        "                   .split_by_rand_pct(0.1 , seed = 42)\n",
        "                   .databunch(bs=bs, bptt=bptt))\n",
        "\n",
        "#data_clas.save('data_clas.pkl')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/fastai/core.py:302: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return np.array(a, dtype=dtype, **kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "LOrSh7T2HQfo",
        "outputId": "7b72174a-1de0-4ded-980a-c536d35446e7"
      },
      "source": [
        "del(data_clas)\n",
        "data_clas = load_data(path, 'data_clas.pkl', bs=bs , bptt = bptt)\n",
        "data_clas.show_batch()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>idx</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>part last modify computer graphics resource list weekly post part last change april many faqs include list available archive site pit manager mit edu alias rtfm mit edu directory pub usenet news answer name faq archive appear archive name line</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>european sit carry add xxunk available radiance xxunk xxunk se pub sipp sipp tar z sipp scan line z buffer phong shade renderer jonas xxunk jonas xxunk se xxunk fr xxunk vm pray ray tracer spd nff many non spd</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>car radio park lot thankful strong radio miles pittsburgh xxunk usually good believe pick middle day xxbos anyone really believe cap beat let xxunk pen may xxunk one game put definitely lose one game remember regular season mean much come</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>might except might something x windows pcs know use think good email xxunk xxunk gov au dv x common xxunk xxunk corporation xxunk x software use dv x yet read xxunk xxunk send sound pretty great allow multiple do machine</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>g pts ashton berube macinnis musil nieuwendyk otto paslawski ranheim reichel roberts skrudland stern suter yawney san jose power play scorer g pts garpenlov gaudreau kisio odgers wood vancouver los angeles first period los angeles robitaille gretzky sandstrom vancouver babych</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "rqDq9kx_ITAK",
        "outputId": "36d845a7-4306-449b-dfae-5dd6c82bb1f6"
      },
      "source": [
        "# Like before we will load Data for Backward Model\n",
        "data_clas_bwd = load_data(path, 'data_clas.pkl', bs=bs, bptt = bptt ,  backwards=True)\n",
        "data_clas_bwd.show_batch()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>idx</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>personally take hey streak unbeaten season regular far unbeaten game year last finals pen meet row blackhawks chicago tie streak playoff streak pen streak win game xxunk want might xxbos xxunk kiss xxunk hint siggraph xxunk xxunk g e surface</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>system software engineer navy xxunk sponsor maryland bethesda center research taylor david formerly center warfare surface naval division carderock june tuesday seminar reality virtual visualization scientific navy presentations call nd xxbos lssu maine xxbos xxunk also dve right xxunk wdve</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>use shit like play canucks xxunk first though big come probert win detroit think yes series playoff intense possibly war seven even maybe six wing though xxunk three two win might toronto playoffs lousy montreal find soon xxunk much leaf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>basis xxunk state xxunk lease current oilers community business northlands office political hold power wake want pocklington xxbos source c even maybe algorithm understand easy anybody surface two intersections problem xxbos claim com ibm xxunk xxunk rate clock doubt seriously</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>idl lang comp also see available discount quantity educational cost progress version mac windows microsoft sun sgi rs ibm hp ultrix vms dec environments windows ms motif look open applications idl gui build system base widget map xxunk statistics basic</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nGT3Uf4Ilmq"
      },
      "source": [
        "## Fine-tuning the forward classifier\n",
        "\n",
        "The classifier needs a little less dropout, so we pass drop_mult=0.5 to multiply all the dropouts by this amount (it's easier than adjusting all the five different values manually). We don't load the pretrained model, but instead our fine-tuned encoder from the previous section."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "I-oiKo27Idkf",
        "outputId": "fe600a13-a485-4fcc-86e8-e18f071096c4"
      },
      "source": [
        "learn = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=0.5, pretrained=False)\n",
        "learn.load_encoder('fwd_enc')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-c4b51095597a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_classifier_learner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_clas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAWD_LSTM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_mult\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fwd_enc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/text/learner.py\u001b[0m in \u001b[0;36mtext_classifier_learner\u001b[0;34m(data, arch, bptt, max_len, config, pretrained, drop_mult, lin_ftrs, ps, **learn_kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m                             ps:Collection[float]=None, **learn_kwargs) -> 'TextClassifierLearner':\n\u001b[1;32m    292\u001b[0m     \u001b[0;34m\"Create a `Learner` with a text classifier from `data` and `arch`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m     model = get_text_classifier(arch, len(data.vocab.itos), data.c, bptt=bptt, max_len=max_len,\n\u001b[0m\u001b[1;32m    294\u001b[0m                                 config=config, drop_mult=drop_mult, lin_ftrs=lin_ftrs, ps=ps)\n\u001b[1;32m    295\u001b[0m     \u001b[0mmeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_model_meta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0march\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/basic_data.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, k)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl_tfms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdl_tfms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_check\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mno_check\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/basic_data.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, k)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/basic_data.py\u001b[0m in \u001b[0;36mDataLoader___getattr__\u001b[0;34m(dl, k)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mintercept_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mDataLoader___getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattr__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader___getattr__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/text/data.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, k)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mite_len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mallocate_buffers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/data_block.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, k)\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 647\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: c"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsGBUJBfIqpz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}